{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ktFt6IzKJkSn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_JoUdRaiIwo4"
   },
   "outputs": [],
   "source": [
    "#Loading data from the Github repository to colab notebook\n",
    "filename = '../Dataset/crx.data'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "0ZmzTR-CJra-",
    "outputId": "3a9c3ce4-da94-4be8-9415-b68b629f10a9"
   },
   "outputs": [],
   "source": [
    "# Loading the data using pandas\n",
    "\n",
    "credData = pd.read_csv(filename,sep=\",\",header = None,na_values = \"?\")\n",
    "credData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "rXYA47JRKVz-",
    "outputId": "f8f7d32e-a973-4725-ce23-1ac1d9cda564"
   },
   "outputs": [],
   "source": [
    "# Changing the Classes to 1 & 0\n",
    "credData.loc[credData[15] == '+' , 15] = 1\n",
    "credData.loc[credData[15] == '-' , 15] = 0\n",
    "credData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "R9-NFhigmokr",
    "outputId": "7b6851a7-0975-4d7b-e169-ad0139cc9143"
   },
   "outputs": [],
   "source": [
    "# Dropping all the rows with na values\n",
    "newcred = credData.dropna(axis = 0)\n",
    "newcred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vxzQZpXMZZN6"
   },
   "outputs": [],
   "source": [
    "# Seperating the categorical variables to make dummy variables\n",
    "\n",
    "credCat = pd.get_dummies(newcred[[0,3,4,5,6,8,9,11,12]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "__Gup8InbTmf"
   },
   "outputs": [],
   "source": [
    "# Seperating the numerical variables\n",
    "\n",
    "credNum = newcred[[1,2,7,10,13,14]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "5S_Icyu1r8YJ",
    "outputId": "8957c4c4-311a-4d97-925c-cea2a62e43d2"
   },
   "outputs": [],
   "source": [
    "# Making the X variable which is a concatenation of categorical and numerical data\n",
    "\n",
    "X = pd.concat([credCat,credNum],axis = 1)\n",
    "print(X.shape)\n",
    "\n",
    "# Seperating the label as y variable\n",
    "y = pd.Series(newcred[15], dtype=\"int\")\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "ZflX7J-5GtY_",
    "outputId": "f73b2446-8468-48b2-c103-073cfdbbb038"
   },
   "outputs": [],
   "source": [
    "# Normalising the data sets\n",
    "# Import library function\n",
    "from sklearn import preprocessing\n",
    "# Creating the scaling function\n",
    "minmaxScaler = preprocessing.MinMaxScaler()\n",
    "# Transforming with the scaler function\n",
    "X_tran = pd.DataFrame(minmaxScaler.fit_transform(X))\n",
    "# Printing the output\n",
    "X_tran.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iJiHJ6zWJ9y_"
   },
   "outputs": [],
   "source": [
    "# Splitting the data set to train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tran, y, test_size=0.3, random_state=123)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "00V4_ZMzu4kz"
   },
   "source": [
    " **Weighted Averaging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wSApjeqSu4Ft"
   },
   "outputs": [],
   "source": [
    "# Defining three base models\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "model1 = LogisticRegression(random_state=123)\n",
    "model2 = KNeighborsClassifier(n_neighbors=5)\n",
    "model3 = RandomForestClassifier(n_estimators=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "nx5Fct-2LaPU",
    "outputId": "c7f54f79-9cbc-4055-9263-965183c3b5dc"
   },
   "outputs": [],
   "source": [
    "# Fitting all three models on the training data\n",
    "model1.fit(X_train,y_train)\n",
    "model2.fit(X_train,y_train)\n",
    "model3.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jstn8nwdvQu7"
   },
   "outputs": [],
   "source": [
    "# Predicting probabilities of each model on the test set\n",
    "pred1=model1.predict_proba(X_test)\n",
    "pred2=model2.predict_proba(X_test)\n",
    "pred3=model3.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZRDIZfm5feFn"
   },
   "source": [
    "**Iteration 1 : For Weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SPXluxfwvfgI"
   },
   "outputs": [],
   "source": [
    "# Calculating the ensemble prediction by applying weights for each prediction\n",
    "ensemblepred=(pred1 *0.60+pred2 * 0.20+pred3 * 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "A9LQ66h6PWDh",
    "outputId": "78d16f4b-eca5-4f08-9501-f642de036dd3"
   },
   "outputs": [],
   "source": [
    "# Displaying first 4 rows of the ensemble predictions\n",
    "ensemblepred[0:4,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "L9AVMddCviVh",
    "outputId": "49aa6bd6-a79a-4d13-de5a-21a0e2daab94"
   },
   "outputs": [],
   "source": [
    "# Printing the order of classes for each model\n",
    "print(model1.classes_)\n",
    "print(model2.classes_)\n",
    "print(model3.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "GspYgLGNvh55",
    "outputId": "890691cd-bf7b-4e18-8e5e-acedbdf72360"
   },
   "outputs": [],
   "source": [
    "# Generating predictions from probabilities\n",
    "import numpy as np\n",
    "pred = np.argmax(ensemblepred,axis = 1)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "rFtV2ZAmwAGo",
    "outputId": "07c507ed-51be-407f-e1d2-3868e922e389"
   },
   "outputs": [],
   "source": [
    "# Generating confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusionMatrix = confusion_matrix(y_test, pred)\n",
    "print(confusionMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "0DM0sQcAwGhA",
    "outputId": "3cd7260e-75b3-4878-f39d-f0b4cb4182ee"
   },
   "outputs": [],
   "source": [
    "# Generating classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J8MwiS7Zft8F"
   },
   "source": [
    "**Iteration 2 of weights**\n",
    "\n",
    "Let us now try a different set of weights and see its effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "st9LnPLmf5eD"
   },
   "outputs": [],
   "source": [
    "# Calculating the ensemble prediction by applying weights for each prediction\n",
    "ensemblepred=(pred1 *0.70+pred2 * 0.15+pred3 * 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "of3bUj7xf5V9"
   },
   "outputs": [],
   "source": [
    "# Generating predictions from probabilities\n",
    "import numpy as np\n",
    "pred = np.argmax(ensemblepred,axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "HVNxhOkFf5Rm",
    "outputId": "a116a5b5-4ecf-4769-a60f-e592aa7bc59c"
   },
   "outputs": [],
   "source": [
    "# Generating confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusionMatrix = confusion_matrix(y_test, pred)\n",
    "print(confusionMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "rmgQfqDyf5QV",
    "outputId": "eac767a3-7174-4cf3-b022-31f04761442c"
   },
   "outputs": [],
   "source": [
    "# Generating classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Exercise 15.03 : Ensemble learning - Weighted Averaging",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
