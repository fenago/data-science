{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ktFt6IzKJkSn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_JoUdRaiIwo4"
   },
   "outputs": [],
   "source": [
    "#Loading data from the Github repository to colab notebook\n",
    "filename = 'https://raw.githubusercontent.com/PacktWorkshops/The-Data-Science-Workshop/master/Chapter15/Dataset/crx.data'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "0ZmzTR-CJra-",
    "outputId": "c01af986-4314-4ca0-a4e2-6b5b2c002875"
   },
   "outputs": [],
   "source": [
    "# Loading the data using pandas\n",
    "\n",
    "credData = pd.read_csv(filename,sep=\",\",header = None,na_values = \"?\")\n",
    "credData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "rXYA47JRKVz-",
    "outputId": "e154e978-a22d-44fc-fb58-97bafd8cabea"
   },
   "outputs": [],
   "source": [
    "# Changing the Classes to 1 & 0\n",
    "credData.loc[credData[15] == '+' , 15] = 1\n",
    "credData.loc[credData[15] == '-' , 15] = 0\n",
    "credData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "R9-NFhigmokr",
    "outputId": "6dc85c46-9a39-4096-bfb0-e5587344a6f0"
   },
   "outputs": [],
   "source": [
    "# Dropping all the rows with na values\n",
    "newcred = credData.dropna(axis = 0)\n",
    "newcred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vxzQZpXMZZN6"
   },
   "outputs": [],
   "source": [
    "# Seperating the categorical variables to make dummy variables\n",
    "\n",
    "credCat = pd.get_dummies(newcred[[0,3,4,5,6,8,9,11,12]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "__Gup8InbTmf"
   },
   "outputs": [],
   "source": [
    "# Seperating the numerical variables\n",
    "\n",
    "credNum = newcred[[1,2,7,10,13,14]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "5S_Icyu1r8YJ",
    "outputId": "964942b8-d020-4a58-ed8c-f3afcf1d6fec"
   },
   "outputs": [],
   "source": [
    "# Making the X variable which is a concatenation of categorical and numerical data\n",
    "\n",
    "X = pd.concat([credCat,credNum],axis = 1)\n",
    "print(X.shape)\n",
    "\n",
    "# Seperating the label as y variable\n",
    "y = pd.Series(newcred[15], dtype=\"int\")\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "ZflX7J-5GtY_",
    "outputId": "fe084eda-8e2a-4705-c0f3-461516714b91"
   },
   "outputs": [],
   "source": [
    "# Normalising the data sets\n",
    "# Import library function\n",
    "from sklearn import preprocessing\n",
    "# Creating the scaling function\n",
    "minmaxScaler = preprocessing.MinMaxScaler()\n",
    "# Transforming with the scaler function\n",
    "X_tran = pd.DataFrame(minmaxScaler.fit_transform(X))\n",
    "# Printing the output\n",
    "X_tran.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iJiHJ6zWJ9y_"
   },
   "outputs": [],
   "source": [
    "# Splitting the data set to train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tran, y, test_size=0.3, random_state=123)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "00V4_ZMzu4kz"
   },
   "source": [
    "**Averaging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wSApjeqSu4Ft"
   },
   "outputs": [],
   "source": [
    "# Defining three base models\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "model1 = LogisticRegression(random_state=123)\n",
    "model2 = KNeighborsClassifier(n_neighbors=5)\n",
    "model3 = RandomForestClassifier(n_estimators=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "nx5Fct-2LaPU",
    "outputId": "0e6a87af-7122-4ba9-92b1-4546c63ce3e5"
   },
   "outputs": [],
   "source": [
    "# Fitting all three models on the training data\n",
    "model1.fit(X_train,y_train)\n",
    "model2.fit(X_train,y_train)\n",
    "model3.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jstn8nwdvQu7"
   },
   "outputs": [],
   "source": [
    "# Predicting probabilities of each model on the test set\n",
    "pred1=model1.predict_proba(X_test)\n",
    "pred2=model2.predict_proba(X_test)\n",
    "pred3=model3.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SPXluxfwvfgI"
   },
   "outputs": [],
   "source": [
    "# Calculating the ensemble prediction by averaging three base model predictions\n",
    "ensemblepred=(pred1+pred2+pred3)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "A9LQ66h6PWDh",
    "outputId": "aa921ae8-fa9a-4ff3-f5dd-6281fc72aa47"
   },
   "outputs": [],
   "source": [
    "# Displaying first 4 rows of the ensemble predictions\n",
    "ensemblepred[0:4,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "L9AVMddCviVh",
    "outputId": "604c5775-c2e6-47fe-a9d8-a8b59f492b83"
   },
   "outputs": [],
   "source": [
    "# Printing the order of classes for each model\n",
    "print(model1.classes_)\n",
    "print(model2.classes_)\n",
    "print(model3.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "GspYgLGNvh55",
    "outputId": "bab6ba15-c5e7-4e03-d5b5-7326f5d94529"
   },
   "outputs": [],
   "source": [
    "# Generating predictions from probabilities\n",
    "import numpy as np\n",
    "pred = np.argmax(ensemblepred,axis = 1)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "rFtV2ZAmwAGo",
    "outputId": "dd7650a3-fc71-4cf6-af82-ffe0df424b2f"
   },
   "outputs": [],
   "source": [
    "# Generating confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusionMatrix = confusion_matrix(y_test, pred)\n",
    "print(confusionMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "0DM0sQcAwGhA",
    "outputId": "b3f488b0-0098-4331-a4b1-905326ce446d"
   },
   "outputs": [],
   "source": [
    "# Generating classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Exercise 15.02 : Ensemble learning - Averaging",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
