{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ktFt6IzKJkSn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_JoUdRaiIwo4"
   },
   "outputs": [],
   "source": [
    "#Loading data from the Github repository to colab notebook\n",
    "filename = '../Dataset/crx.data'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "0ZmzTR-CJra-",
    "outputId": "4b7ddb3f-9f1a-4b93-9ca7-291a4465c9f4"
   },
   "outputs": [],
   "source": [
    "# Loading the data using pandas\n",
    "\n",
    "credData = pd.read_csv(filename,sep=\",\",header = None,na_values = \"?\")\n",
    "credData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "rXYA47JRKVz-",
    "outputId": "b7fb9867-f90f-481b-81e4-0c46992069ac"
   },
   "outputs": [],
   "source": [
    "# Changing the Classes to 1 & 0\n",
    "credData.loc[credData[15] == '+' , 15] = 1\n",
    "credData.loc[credData[15] == '-' , 15] = 0\n",
    "credData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "R9-NFhigmokr",
    "outputId": "2e4afa41-0802-468d-9a78-ecf2539b0eff"
   },
   "outputs": [],
   "source": [
    "# Dropping all the rows with na values\n",
    "newcred = credData.dropna(axis = 0)\n",
    "newcred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vxzQZpXMZZN6"
   },
   "outputs": [],
   "source": [
    "# Seperating the categorical variables to make dummy variables\n",
    "\n",
    "credCat = pd.get_dummies(newcred[[0,3,4,5,6,8,9,11,12]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "__Gup8InbTmf"
   },
   "outputs": [],
   "source": [
    "# Seperating the numerical variables\n",
    "\n",
    "credNum = newcred[[1,2,7,10,13,14]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "5S_Icyu1r8YJ",
    "outputId": "8aa62a42-b0b6-4107-dd78-6a46b8769fe9"
   },
   "outputs": [],
   "source": [
    "# Making the X variable which is a concatenation of categorical and numerical data\n",
    "\n",
    "X = pd.concat([credCat,credNum],axis = 1)\n",
    "print(X.shape)\n",
    "\n",
    "# Seperating the label as y variable\n",
    "y = pd.Series(newcred[15], dtype=\"int\")\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "ZflX7J-5GtY_",
    "outputId": "57d09059-56f5-4ec7-9a71-055f0c7dfe03"
   },
   "outputs": [],
   "source": [
    "# Normalising the data sets\n",
    "# Import library function\n",
    "from sklearn import preprocessing\n",
    "# Creating the scaling function\n",
    "minmaxScaler = preprocessing.MinMaxScaler()\n",
    "# Transforming with the scaler function\n",
    "X_tran = pd.DataFrame(minmaxScaler.fit_transform(X))\n",
    "# Printing the output\n",
    "X_tran.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iJiHJ6zWJ9y_"
   },
   "outputs": [],
   "source": [
    "# Splitting the data set to train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tran, y, test_size=0.3, random_state=123)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oy7wgbV-P9jX"
   },
   "source": [
    "**Bagging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0qqhL7KlP8NU"
   },
   "outputs": [],
   "source": [
    "# Defining the base learner\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "bl1 = LogisticRegression(random_state=123) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kz8qHh5LP7pR"
   },
   "outputs": [],
   "source": [
    "# Creating the bagging meta learner\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "baggingLearner = BaggingClassifier(base_estimator=bl1, n_estimators=15, max_samples=0.7, max_features=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iryLpSslP7kd"
   },
   "outputs": [],
   "source": [
    "# Fitting the model using the meta learner\n",
    "model = baggingLearner.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5MbgjmAwP7jt"
   },
   "outputs": [],
   "source": [
    "# Predicting on the test set using the model\n",
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ISgI6OCKP7eD",
    "outputId": "ede6b84c-8274-4c98-9c0d-9084fdc87f2d"
   },
   "outputs": [],
   "source": [
    "# Printing the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "c9MW76CnP7dX",
    "outputId": "4e8c7a8d-6465-457e-edfd-25b995ba149f"
   },
   "outputs": [],
   "source": [
    "# Printing the classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e5LGI1uzOYol"
   },
   "source": [
    "**Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KCvWasKVORqE"
   },
   "outputs": [],
   "source": [
    "# Defining the base learner\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "bl1 = RandomForestClassifier(random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nGSJM0o5ORai"
   },
   "outputs": [],
   "source": [
    "# Defining the boosting meta learner\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "boosting = AdaBoostClassifier(base_estimator=bl1, n_estimators=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v5W7XsSWORME"
   },
   "outputs": [],
   "source": [
    "# Fitting the model on the training set\n",
    "\n",
    "model = boosting.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "svm9rCZhOQ_B"
   },
   "outputs": [],
   "source": [
    "# Getting the predictions from the boosting model\n",
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "xYLqK0YJOQzb",
    "outputId": "cb203cad-891c-46a9-ef6f-023674d9f737"
   },
   "outputs": [],
   "source": [
    "# Printing the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, pred))\n",
    "\n",
    "# Printing the classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n4I7ujXBxnNj"
   },
   "source": [
    "**Stacking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TsNS-IAN3urW"
   },
   "outputs": [],
   "source": [
    "# Importing the meta learner and base learners\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "bl1 = KNeighborsClassifier(n_neighbors=5)\n",
    "bl2 = LogisticRegression(random_state=123) \n",
    "ml = RandomForestClassifier(random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "Z6BvZ7Jzxmph",
    "outputId": "10663823-d40a-4917-cb9e-36146e5bda63"
   },
   "outputs": [],
   "source": [
    "# Creating the stacking classifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "stackclf = StackingClassifier(classifiers=[bl1, bl2], \n",
    "                          meta_classifier=ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "LVq5ljcdx4R4",
    "outputId": "1792b91d-bb61-4583-e46c-57fe04c931f0"
   },
   "outputs": [],
   "source": [
    "# Fitting the model on the training set\n",
    "model = stackclf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R9kr6DBeyKuX"
   },
   "outputs": [],
   "source": [
    "# Generating predictions on test set\n",
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "BMFA_SivyVRv",
    "outputId": "0deb98b3-43a2-466a-a5f2-25d0f68094e3"
   },
   "outputs": [],
   "source": [
    "# Printing the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, pred))\n",
    "\n",
    "# Printing the classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, pred))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Activity 15.02 : Comparison of ensemble learning techniques",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
